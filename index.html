<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Kevin Li</title>
    
    <meta name="author" content="Kevin Li">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="icon" type="image/png" href="./images/prof_pic.png">
    <!-- <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon"> -->
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.7.1/jquery.min.js"></script>
    <script src="index.js"></script>
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Kevin (Yu-Teng) Li
                </p>
                <p>
                  I am an Applied Research Scientist at Adobe Firefly, working on foundation model training and multimodal research. Most recently I co-led the multimodal pretraining of Firefly Image 5, which includes textual editing, single-image reference generation, layer generation, and text-to-image workflows. 
                </p>
                <p>
                  I previously graduated from University of California, Berkeley with a B.S. in Electrical Engineering and Computer Sciences, where I did my research in <a href="https://arxiv.org/abs/2306.11180">Active Learning in Segmentation</a> under the supervision Trevor Darrell.
                </p>
                <p><strong>This website currently is still under construction! ðŸš§</strong></p>
                <p style="text-align:center">
                  <a href="mailto:yutengli@berkeley.edu">Email</a> &nbsp;/&nbsp;
                  <a href="data/resume.pdf">CV</a> &nbsp;/&nbsp;
                  <!-- <a href="">Google Scholar</a> &nbsp;/&nbsp; -->
                  <a href="https://x.com/curiouskid423">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/yutengli/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://github.com/thekevinli">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/prof_pic.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 3%;" alt="profile photo" src="images/prof_pic.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px 0;width:100%;vertical-align:middle">
                <h2>Research & Industry Projects</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
            <tr style="background-color: #ffffd0;">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one; display: block; margin: auto">
                  <img src="images/unifusion_arch.png" width=100%>
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://thekevinli.github.io/unifusion/">
                  <span class="papertitle">UniFusion: Vision-Language Model as Unified Encoder for Image Generation</span>
                </a>
                <br>
                <strong>Yu-Teng Li*</strong>,
                <a href="">Manuel Brack*</a>,
                <a href="">Sudeep Katakol</a>,
                <a href="">Hareesh Ravi</a>,
                <a href="">Ajinkya Kale</a>
                <br>
                <em>ArXiv</em>, 2025
                <p></p>
                <p>
                  The first architecture that uses only VLM as input-condition encoder without auxiliary signals from VAE or CLIP to do editing. The unified encoder framework enables emergent capabilities such as zero-shot multi-ref generation when trained on single-ref pairs.
                </p>
              </td>
            </tr>

            <tr style="background-color: #ffffd0;">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one; display: block; margin: auto">
                  <img src="images/firefly_image_5.png" width=100%>
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="">
                  <span class="papertitle">Firefly Image 5</span>
                </a>
                <br>
                <span style="padding: 3px 0; display: block;"><strong>Multimodal pretraining</strong> (textual editing, single-reference generation, layer generation)</span>
                <span><em>October 2025</em></span>
                <p></p>
                <p>
                  I was in charge of multimodal pretraining of Firefly Image 5 model for workflows of textual editing, single-image reference generation and layer generation. Throughout the development, I drive decisions on the architecture and training recipes, handling ~1000 GPU scale of distributed training on a daily basis from July to Oct 2025.
                </p>
              </td>
            </tr>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one; display: block; margin: auto">
                  <img src="images/firefly_image_4.jpg" width=100%>
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://blog.adobe.com/en/publish/2025/04/24/adobe-firefly-next-evolution-creative-ai-is-here">
                  <span class="papertitle">Firefly Image 4</span>
                </a>
                <br>
                <span style="padding: 3px 0; display: block;"><strong>Foundation model pretraining & SFT</strong></span>
                <span><em>April 2025</em></span>
                <p></p>
                <p>
                  I am part of the pretraining team and in charge of post-training (SFT). Lorem ipsum dolor sit amet, dicta legere omittam an eum, ius atqui nusquam in. In tibique detraxit vim, eos diam autem consequuntur ei. Sit probo libris at, cum nisl facete civibus ei, novum paulo nam ex. In mei error aperiam intellegam.
                </p>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one; display: block; margin: auto">
                  <img src="images/firefly_image_3.png" width=100%>
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://helpx.adobe.com/firefly/web/work-with-enterprise-features/train-custom-models/custom-models-overview.html">
                  <span class="papertitle">Firefly Image 3 Custom Models</span>
                </a>
                <br>
                <span><em>August 2024</em></span>
                <p></p>
                <p>
                  I led the personalization effort of Firefly Image 3 called Custom Models, which caters to enterprise customers. I developed the training recipe, model architecture, and integrated the finetuning pipeline into prodcution service. Custom Model is... Lorem ipsum dolor sit amet, dicta legere omittam an eum, ius atqui nusquam in. In tibique detraxit vim, eos diam autem consequuntur ei.
                </p>
              </td>
            </tr>
          
          

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one; display: block; margin: auto">
                  <img src="images/halo.png" width=100%>
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2306.11180">
                  <span class="papertitle">Hyperbolic Active Learning for Semantic Segmentation under Domain Shift</span>
                </a>
                <br>
                <a href="">Luca Franco*</a>,
                <a href="">Paolo Mandica*</a>,
                <a href="">Konstantinos Kallidromitis</a>,
                <a href="">Devin Guillory</a>,
                <strong>Yu-Teng Li</strong>,
                <a href="">Trevor Darrell</a>,
                <a href="">Fabio Galasso</a>
                <br>
                <em>ICML</em>, 2024
                <br>
                <p></p>
                <p>
                  HALO introduces a hyperbolic neural network approach to pixel-based active learning (AL) for semantic segmentation, and is the first active AL method to surpass the performance of supervised domain adaptation with just 1% of labeled pixels.
                </p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one; display: block; margin: auto">
                  <img src="images/lunar_lander.gif" width=100%>
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/pdf/2212.10712">
                  <span class="papertitle">Neighboring state-based RL Exploration</span>
                </a>
                <br>
                <a href="">Jeffery Cheng*</a>,
                <strong>Yu-Teng Li*</strong>,
                <a href="">Justin Lin*</a>,
                <a href="">Pedro Pachuca*</a>
                <br>
                <em>ArXiv</em>, 2022
                <br>
                <p></p>
                <p>
                  <a href="https://github.com/thekevinli/rho_exploration">Code</a>. Lorem ipsum dolor sit amet, dicta legere omittam an eum, ius atqui nusquam in. In tibique detraxit vim, eos diam autem consequuntur ei. Sit probo libris at, cum nisl facete civibus ei, novum paulo nam ex. In mei error aperiam intellegam.
                </p>
              </td>
            </tr>
    <!-- <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src="images/scTIE_pipeline.jpg" width=100%>
        </div>

      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://genome.cshlp.org/content/34/1/119.full">
          <span class="papertitle">scTIE: data integration and inference of gene regulation using single-cell temporal multimodal data</span>
        </a>
        <br>
        <a href="">Yingxin Lin</a>,
        <a href="">Tung-Yu Wu</a>,
        <a href="">Xi Chen</a>,
        <a href="">Sheng Wan</a>,
        <strong>Kevin Li</strong>,
        <a href="">Jingxue Xin</a>,
        <a href="">Jean Y.H. Yang</a>,
        <a href="">Wing H. Wong</a>
        <a href="">Y.X. Rachel Wang</a>,
        <br>
        <em>Genome Research</em>, 2023
        <br>
        <p></p>
        <p>
          Using optimal transport to infer regulatory relationships predictive of cellular state changes
          in single-cell temporal and multimodal data.
        </p>
      </td>
    </tr> -->
    </tbody></table>

          <!--
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
              <td width="75%" valign="center">
                <a href="https://cvpr.thecvf.com/Conferences/2024/Organizers">Area Chair, CVPR 2024</a>
                <br>
                <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
                <br>
                <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                <br>
                <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Award Committee Member, CVPR 2021</a>
                <br>
                <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                <br>
                <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/cs188.jpg" alt="cs188">
              </td>
              <td width="75%" valign="center">
                <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
                <br>
                <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
                <br>
                <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
              </td>
            </tr>
            

            <tr>
              <td align="center" style="padding:20px;width:25%;vertical-align:middle">
                <h2>Basically <br> Blog Posts</h2>
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                <br>
                <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
                <br>
                <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
                <br>
                <a href="https://jonbarron.info/data/cvpr2023_llm_workshop_annotated.pdf">Scholars & Big Models: How Can Academics Adapt?</a>
              </td>
            </tr>
            
            
          </tbody></table>
        -->

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Website source code from <a href="https://github.com/jonbarron/jonbarron_website">here</a>. 
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
